import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder

# 中文字型設定
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
plt.rcParams['axes.unicode_minus'] = False

# 1. 讀取資料
df = pd.read_csv('your_data.csv, encoding='big5')
# 2. 篩選數位素養在合理範圍內（0~10）
df = df[df['數位素養'].between(0, 10)]

# 3. 地區分類
def map_region(code):
    if code in [1, 2, 3, 7, 8, 18, 19]:
        return '北部'
    elif code in [4, 9, 10, 11, 12]:
        return '中部'
    elif code in [5, 6, 13, 14, 20]:
        return '南部'
    elif code in [16, 17]:
        return '東部'
    else:
        return '其他'

df['地區'] = df['v1'].apply(map_region)

# 4. 分群標籤處理（0=低，1=高），排除中間群體
df_extreme = df[(df['數位素養'] <= 4) | (df['數位素養'] >= 7)].copy()
df_extreme['素養分類'] = df_extreme['數位素養'].apply(lambda x: 1 if x >= 7 else 0)

# 5. 特徵欄位
feature_cols = [yourfeature]

# 6. 移除 98/99 異常值
for col in feature_cols:
    df_extreme = df_extreme[~df_extreme[col].isin([98, 99])]

# 7. 資料分割與標準化
X = df_extreme[feature_cols]
y = df_extreme['素養分類']
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 8. 使用 GridSearchCV 調整 KNN 超參數
param_grid = {
    'n_neighbors': list(range(1, 21)),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid.fit(X_train_scaled, y_train)

best_knn = grid.best_estimator_
print(f"\n✅ 最佳參數組合：{grid.best_params_}")
print(f"✅ 最佳交叉驗證準確率：{grid.best_score_:.4f}")

# 9. 使用最佳模型預測與測試資料評估
y_pred = best_knn.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
print("\n📊 KNN 最佳模型在測試資料上的準確率：{:.2f}%".format(accuracy * 100))

# 10. 關聯規則分析（依地區與素養分類進行）
def encode_for_apriori(dataframe, columns):
    df_bin = dataframe[columns].copy()
    for col in df_bin.columns:
        df_bin[col] = col + '_' + df_bin[col].astype(str)
    records = df_bin.values.tolist()
    te = TransactionEncoder()
    te_ary = te.fit(records).transform(records)
    return pd.DataFrame(te_ary, columns=te.columns_)

regions = ['北部', '中部', '南部', '東部']
for region in regions:
    for label, label_name in zip([0, 1], ['低', '高']):
        subset = df_extreme[(df_extreme['地區'] == region) & (df_extreme['素養分類'] == label)]
        if not subset.empty:
            print(f"\n🔎 正在處理：{region} - {label_name} 數位素養...")
            encoded = encode_for_apriori(subset, feature_cols)
            freq_items = apriori(encoded, min_support=0.3, use_colnames=True)
            rules = association_rules(freq_items, metric='confidence', min_threshold=0.8)
            rules = rules[
                (rules['lift'] >= 1.1) &
                (rules['antecedents'].apply(lambda x: len(x) >= 3)) &
                (rules['consequents'].apply(lambda x: len(x) >= 2))
            ]
            print(f"\n📌 {region} - {label_name} 數位素養 前10條關聯規則：")
            print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))

# 11. 混淆矩陣與分類報告
print("\n🔍 分類報告（Classification Report）：")
print(classification_report(y_test, y_pred, target_names=["低數位素養", "高數位素養"]))

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["低數位素養", "高數位素養"])
disp.plot(cmap=plt.cm.Blues)
plt.title("📌 KNN 最佳模型分類混淆矩陣")
plt.show()
