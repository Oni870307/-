import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from sklearn.linear_model import LogisticRegression
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import seaborn as sns

# ä¸­æ–‡å­—å‹è¨­å®š
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
plt.rcParams['axes.unicode_minus'] = False

# 1. è®€å–è³‡æ–™
df = pd.read_csv('your_data.csv, encoding='big5')

# 2. ç¯©é¸æ•¸ä½ç´ é¤Šåœ¨åˆç†ç¯„åœå…§ï¼ˆ0~10ï¼‰
df = df[df['æ•¸ä½ç´ é¤Š'].between(0, 10)]

# 3. åœ°å€åˆ†é¡
def map_region(code):
    if code in [1, 2, 3, 7, 8, 18, 19]:
        return 'åŒ—éƒ¨'
    elif code in [4, 9, 10, 11, 12]:
        return 'ä¸­éƒ¨'
    elif code in [5, 6, 13, 14, 20]:
        return 'å—éƒ¨'
    elif code in [16, 17]:
        return 'æ±éƒ¨'
    else:
        return 'å…¶ä»–'

df['åœ°å€'] = df['v1'].apply(map_region)

# 4. åˆ†ç¾¤æ¨™ç±¤è™•ç†ï¼ˆ0=ä½ï¼Œ1=é«˜ï¼‰ï¼Œæ’é™¤ä¸­é–“ç¾¤é«”
df_extreme = df[(df['æ•¸ä½ç´ é¤Š'] <= 4) | (df['æ•¸ä½ç´ é¤Š'] >= 7)].copy()
df_extreme['ç´ é¤Šåˆ†é¡'] = df_extreme['æ•¸ä½ç´ é¤Š'].apply(lambda x: 1 if x >= 7 else 0)

# 5. ç‰¹å¾µæ¬„ä½
feature_cols = [yourfeature]

# 6. ç§»é™¤ 98/99 ç•°å¸¸å€¼
for col in feature_cols:
    df_extreme = df_extreme[~df_extreme[col].isin([98, 99])]

# 6.1 é¡¯ç¤ºçš®çˆ¾æ£®ç›¸é—œä¿‚æ•¸ç†±åŠ›åœ–
df_corr = df_extreme[feature_cols + ['ç´ é¤Šåˆ†é¡']]
corr_matrix = df_corr.corr(method='pearson')
plt.figure(figsize=(16, 12))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', linewidths=0.5,
            cbar_kws={'label': 'çš®çˆ¾æ£®ç›¸é—œä¿‚æ•¸'}, square=True)
plt.title("ğŸ“Š æ•¸ä½ç´ é¤Šåˆ†é¡èˆ‡ç‰¹å¾µä¹‹çš®çˆ¾æ£®ç›¸é—œä¿‚æ•¸ç†±åŠ›åœ–", fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# 7. å»ºç«‹è¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
X = df_extreme[feature_cols]
y = df_extreme['ç´ é¤Šåˆ†é¡']
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)

# 8. ä½¿ç”¨ GridSearchCV èª¿æ•´è¶…åƒæ•¸
param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l2'],  # è‹¥è¦æ¸¬è©¦ l1ï¼Œéœ€æ”¹ç”¨ solver='liblinear'
    'solver': ['lbfgs', 'liblinear']
}
grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')
grid.fit(X_train, y_train)

log_reg = grid.best_estimator_
print(f"âœ… æœ€ä½³åƒæ•¸çµ„åˆï¼š{grid.best_params_}")

# 9. æ¨¡å‹é æ¸¬èˆ‡è©•ä¼°
y_pred = log_reg.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("\nğŸ“Š é‚è¼¯å¼å›æ­¸æœ€ä½³æ¨¡å‹åœ¨æ¥µç«¯åˆ†é¡ä¸Šçš„æº–ç¢ºç‡ï¼š{:.2f}%".format(accuracy * 100))

# 10. é—œè¯è¦å‰‡åˆ†æ
def encode_for_apriori(dataframe, columns):
    df_bin = dataframe[columns].copy()
    for col in df_bin.columns:
        df_bin[col] = df_bin[col].astype(str)
        df_bin[col] = col + '_' + df_bin[col]
    records = df_bin.values.tolist()
    te = TransactionEncoder()
    te_ary = te.fit(records).transform(records)
    return pd.DataFrame(te_ary, columns=te.columns_)

regions = ['åŒ—éƒ¨', 'ä¸­éƒ¨', 'å—éƒ¨', 'æ±éƒ¨']
for region in regions:
    for label, label_name in zip([0, 1], ['ä½', 'é«˜']):
        subset = df_extreme[(df_extreme['åœ°å€'] == region) & (df_extreme['ç´ é¤Šåˆ†é¡'] == label)]
        if not subset.empty:
            print(f"\næ­£åœ¨è™•ç†ï¼š{region} - {label_name} æ•¸ä½ç´ é¤Š...")
            encoded = encode_for_apriori(subset, feature_cols)
            freq_items = apriori(encoded, min_support=0.3, use_colnames=True)
            rules = association_rules(freq_items, metric='confidence', min_threshold=0.8)
            rules = rules[
                (rules['lift'] >= 1.1) &
                (rules['antecedents'].apply(lambda x: len(x) >= 3)) &
                (rules['consequents'].apply(lambda x: len(x) >= 2))
            ]
            print(f"\nğŸ“Œ {region} åœ°å€ - {label_name} æ•¸ä½ç´ é¤Š çš„é—œè¯è¦å‰‡ï¼ˆå‰10æ¢ï¼‰ï¼š")
            print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))

# 11. æ··æ·†çŸ©é™£èˆ‡åˆ†é¡å ±å‘Š
print("\nğŸ” åˆ†é¡å ±å‘Šï¼ˆClassification Reportï¼‰ï¼š")
print(classification_report(y_test, y_pred, target_names=["ä½æ•¸ä½ç´ é¤Š", "é«˜æ•¸ä½ç´ é¤Š"]))

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["ä½æ•¸ä½ç´ é¤Š", "é«˜æ•¸ä½ç´ é¤Š"])
disp.plot(cmap=plt.cm.Blues)
plt.title("ğŸ“Œ é‚è¼¯å¼å›æ­¸åˆ†é¡æ··æ·†çŸ©é™£")
plt.show()
