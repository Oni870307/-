import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from sklearn.svm import SVC
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder

# ä¸­æ–‡å­—å‹è¨­å®š
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
plt.rcParams['axes.unicode_minus'] = False

# 1. è®€å–è³‡æ–™
df = pd.read_csv('your_data.csv, encoding='big5')

# 2. ç¯©é¸æ•¸ä½ç´ é¤Šåœ¨åˆç†ç¯„åœå…§ï¼ˆ0~10ï¼‰
df = df[df['æ•¸ä½ç´ é¤Š'].between(0, 10)]

# 3. åœ°å€åˆ†é¡
def map_region(code):
    if code in [1, 2, 3, 7, 8, 18, 19]:
        return 'åŒ—éƒ¨'
    elif code in [4, 9, 10, 11, 12]:
        return 'ä¸­éƒ¨'
    elif code in [5, 6, 13, 14, 20]:
        return 'å—éƒ¨'
    elif code in [16, 17]:
        return 'æ±éƒ¨'
    else:
        return 'å…¶ä»–'

df['åœ°å€'] = df['v1'].apply(map_region)

# 4. åˆ†ç¾¤æ¨™ç±¤è™•ç†ï¼ˆ0=ä½ï¼Œ1=é«˜ï¼‰ï¼Œæ’é™¤ä¸­é–“ç¾¤é«”
df_extreme = df[(df['æ•¸ä½ç´ é¤Š'] <= 4) | (df['æ•¸ä½ç´ é¤Š'] >= 7)].copy()
df_extreme['ç´ é¤Šåˆ†é¡'] = df_extreme['æ•¸ä½ç´ é¤Š'].apply(lambda x: 1 if x >= 7 else 0)

# 5. ç‰¹å¾µæ¬„ä½
feature_cols = [yourfeature]

# 6. ç§»é™¤ 98/99 ç•°å¸¸å€¼
for col in feature_cols:
    df_extreme = df_extreme[~df_extreme[col].isin([98, 99])]

# 7. è¨“ç·´é›†åˆ‡åˆ†
X = df_extreme[feature_cols]
y = df_extreme['ç´ é¤Šåˆ†é¡']
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)

# 8. è¶…åƒæ•¸æœå°‹ï¼ˆGridSearchCVï¼‰
param_grid = {
    'C': [0.1, 1, 10],
    'gamma': [0.01, 0.1, 1],
    'kernel': ['rbf']
}

grid = GridSearchCV(SVC(probability=True), param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid.fit(X_train, y_train)

# 9. ä½¿ç”¨æœ€ä½³æ¨¡å‹
svm_clf = grid.best_estimator_
print(f"\nâœ… æœ€ä½³åƒæ•¸çµ„åˆï¼š{grid.best_params_}")

# 10. æ¨¡å‹é æ¸¬èˆ‡è©•ä¼°
y_pred = svm_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("\nğŸ“Š SVM æœ€ä½³æ¨¡å‹åœ¨æ¥µç«¯åˆ†é¡ä¸Šçš„æº–ç¢ºç‡ï¼š{:.2f}%".format(accuracy * 100))

# 11. é—œè¯è¦å‰‡åˆ†æï¼ˆä¾åœ°å€ + ç´ é¤Šç¾¤é«”ï¼‰
def encode_for_apriori(dataframe, columns):
    df_bin = dataframe[columns].copy()
    for col in df_bin.columns:
        df_bin[col] = df_bin[col].astype(str)
        df_bin[col] = col + '_' + df_bin[col]
    records = df_bin.values.tolist()
    te = TransactionEncoder()
    te_ary = te.fit(records).transform(records)
    return pd.DataFrame(te_ary, columns=te.columns_)

regions = ['åŒ—éƒ¨', 'ä¸­éƒ¨', 'å—éƒ¨', 'æ±éƒ¨']
for region in regions:
    for label, label_name in zip([0, 1], ['ä½', 'é«˜']):
        subset = df_extreme[(df_extreme['åœ°å€'] == region) & (df_extreme['ç´ é¤Šåˆ†é¡'] == label)]
        if not subset.empty:
            print(f"\næ­£åœ¨è™•ç†ï¼š{region} - {label_name} æ•¸ä½ç´ é¤Š...")
            encoded = encode_for_apriori(subset, feature_cols)
            freq_items = apriori(encoded, min_support=0.3, use_colnames=True)
            rules = association_rules(freq_items, metric='confidence', min_threshold=0.8)
            rules = rules[
                (rules['lift'] >= 1.1) &
                (rules['antecedents'].apply(lambda x: len(x) >= 3)) &
                (rules['consequents'].apply(lambda x: len(x) >= 2))
            ]
            print(f"\nğŸ“Œ {region} åœ°å€ - {label_name} æ•¸ä½ç´ é¤Š çš„é—œè¯è¦å‰‡ï¼ˆå‰10æ¢ï¼‰ï¼š")
            print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10))

# 12. æ··æ·†çŸ©é™£èˆ‡åˆ†é¡å ±å‘Š
print("\nğŸ” åˆ†é¡å ±å‘Šï¼ˆClassification Reportï¼‰ï¼š")
print(classification_report(y_test, y_pred, target_names=["ä½æ•¸ä½ç´ é¤Š", "é«˜æ•¸ä½ç´ é¤Š"]))

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["ä½æ•¸ä½ç´ é¤Š", "é«˜æ•¸ä½ç´ é¤Š"])
disp.plot(cmap=plt.cm.Blues)
plt.title("ğŸ“Œ SVM æœ€ä½³æ¨¡å‹åˆ†é¡æ··æ·†çŸ©é™£")
plt.show()
